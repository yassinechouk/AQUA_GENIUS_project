#!/usr/bin/env python3
"""
Script ULTIME : G√©n√©ration du Dataset Final
Auteur: Yassinechouk
Date: 2025-11-21 18:55:53 UTC

Ce script g√©n√®re le dataset final parfait avec :
‚úÖ 10 INPUTS + 2 OUTPUTS
‚úÖ Unit√©s correctes et conversions
‚úÖ Coh√©rences logiques et physiques
‚úÖ Distribution √©quilibr√©e (50% OFF / 50% ON)
‚úÖ 3 cat√©gories (30% / 50% / 20%)
‚úÖ Correction automatique soil_moisture
‚úÖ Aucune incoh√©rence
"""

import pandas as pd
import numpy as np
import argparse
import logging
import sys
import os
from datetime import datetime

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class FinalDatasetGenerator:
    """G√©n√©rateur du dataset final parfait"""
    
    # ========================================================================
    # D√âFINITION DES VARIABLES
    # ========================================================================
    
    INPUTS = {
        'tmean': {'unit': '¬∞C', 'min': 5, 'max': 45, 'description': 'Temp√©rature moyenne'},
        'tmin': {'unit': '¬∞C', 'min': 0, 'max': 40, 'description': 'Temp√©rature minimale'},
        'tmax': {'unit': '¬∞C', 'min': 10, 'max': 50, 'description': 'Temp√©rature maximale'},
        'humidite': {'unit': '%', 'min': 20, 'max': 95, 'description': 'Humidit√© relative'},
        'Ra': {'unit': 'MJ/m¬≤/j', 'min': 10, 'max': 45, 'description': 'Radiation extraterrestre'},
        'ETo': {'unit': 'mm/j', 'min': 0.5, 'max': 12.0, 'description': '√âvapotranspiration de r√©f√©rence'},
        'VPD': {'unit': 'kPa', 'min': 0.1, 'max': 5.0, 'description': 'D√©ficit de pression de vapeur'},
        'soil_temp': {'unit': '¬∞C', 'min': 5, 'max': 40, 'description': 'Temp√©rature du sol'},
        'soil_moisture': {'unit': '%', 'min': 10, 'max': 70, 'description': 'Humidit√© du sol'},
        'categorie': {'unit': '', 'min': 1, 'max': 3, 'description': 'Cat√©gorie de culture'}
    }
    
    OUTPUTS = {
        'pump_status': {'unit': '', 'values': [0, 1], 'description': 'Statut pompe (0=OFF, 1=ON)'},
        'irrigation_volume': {'unit': 'mm/j', 'min': 0.0, 'max': 15.0, 'description': 'Volume d\'irrigation'}
    }
    
    # Coefficients Kc par cat√©gorie
    KC_VALUES = {
        1: 0.95,  # Faibles besoins (olivier, amandier)
        2: 1.10,  # Besoins mod√©r√©s (bl√©, tomate)
        3: 1.20   # Besoins √©lev√©s (ma√Øs, past√®que)
    }
    
    # Distribution des cat√©gories
    CATEGORY_DISTRIBUTION = {
        1: 0.30,  # 30%
        2: 0.50,  # 50%
        3: 0.20   # 20%
    }
    
    def __init__(self):
        pass
    
    # ========================================================================
    # √âTAPE 1 : CHARGEMENT ET FUSION
    # ========================================================================
    
    def load_merged_data(self, input_file: str) -> pd.DataFrame:
        """Charge le dataset fusionn√©"""
        logger.info("="*70)
        logger.info("üìÇ √âTAPE 1 : CHARGEMENT DES DONN√âES")
        logger.info("="*70)
        
        if not os.path.exists(input_file):
            logger.error(f"‚ùå Fichier introuvable: {input_file}")
            logger.info("\nüí° G√©n√©rez d'abord les donn√©es:")
            logger.info("   python merge_all_sources.py --nasa data/nasa_power.csv --kaggle data/kaggle_tunisia.csv --output data/merged_all.csv")
            sys.exit(1)
        
        df = pd.read_csv(input_file)
        df['date'] = pd.to_datetime(df['date'], errors='coerce')
        
        logger.info(f"  ‚úÖ {len(df)} lignes √ó {len(df.columns)} colonnes")
        logger.info(f"  üìÖ P√©riode: {df['date'].min()} ‚Üí {df['date'].max()}")
        
        return df
    
    # ========================================================================
    # √âTAPE 2 : S√âLECTION ET CONVERSION DES INPUTS
    # ========================================================================
    
    def select_and_convert_inputs(self, df: pd.DataFrame) -> pd.DataFrame:
        """S√©lectionne et convertit les 10 inputs avec unit√©s correctes"""
        logger.info("\n" + "="*70)
        logger.info("üîß √âTAPE 2 : S√âLECTION ET CONVERSION DES INPUTS")
        logger.info("="*70)
        
        df_clean = pd.DataFrame()
        df_clean['date'] = df['date']
        
        for var_name, var_info in self.INPUTS.items():
            logger.info(f"\n  ‚Ä¢ {var_name} ({var_info['description']})")
            logger.info(f"    Unit√©: {var_info['unit']}, Plage: [{var_info['min']}, {var_info['max']}]")
            
            if var_name in df.columns:
                values = df[var_name].copy()
                
                # CONVERSIONS SP√âCIFIQUES
                
                # 1. soil_moisture : convertir 0-1 ‚Üí 0-100%
                if var_name == 'soil_moisture' and values.max() < 10:
                    logger.warning(f"    ‚ö†Ô∏è  Conversion √ó 100 (format d√©cimal d√©tect√©)")
                    values = values * 100
                
                # 2. Temp√©rature : v√©rifier coh√©rence tmin < tmean < tmax
                if var_name == 'tmean':
                    if 'tmin' in df.columns and 'tmax' in df.columns:
                        # Forcer coh√©rence
                        tmin = df['tmin']
                        tmax = df['tmax']
                        values = np.clip(values, tmin, tmax)
                
                # 3. Clipper dans la plage valide
                values = np.clip(values, var_info['min'], var_info['max'])
                
                # 4. CORRECTION SP√âCIALE pour soil_moisture
                if var_name == 'soil_moisture':
                    # V√©rifier si les valeurs sont quasi-constantes
                    if values.std() < 1.0 or pd.Series(values).nunique() < 20:
                        logger.warning(f"    ‚ö†Ô∏è  soil_moisture quasi-constant (std={values.std():.2f}, unique={pd.Series(values).nunique()})")
                        logger.warning(f"    ‚Üí R√©g√©n√©ration intelligente...")
                        
                        # R√©g√©n√©rer avec logique coh√©rente
                        base_moisture = 40  # Moyenne de 40%
                        
                        # Variation bas√©e sur ETo (inversement proportionnel)
                        if 'ETo' in df.columns:
                            eto_effect = -1.5 * (df['ETo'] - df['ETo'].mean())
                        else:
                            eto_effect = 0
                        
                        # Variation saisonni√®re
                        if 'date' in df_clean.columns:
                            day_of_year = df_clean['date'].dt.dayofyear
                            seasonal_effect = 15 * np.sin(2 * np.pi * day_of_year / 365 - np.pi/2)
                        else:
                            seasonal_effect = 0
                        
                        # Bruit al√©atoire
                        np.random.seed(42)
                        random_noise = np.random.normal(0, 5, len(values))
                        
                        # Nouvelle soil_moisture
                        values = base_moisture + eto_effect + seasonal_effect + random_noise
                        values = np.clip(values, var_info['min'], var_info['max'])
                        
                        logger.info(f"    ‚úÖ R√©g√©n√©r√©: min={values.min():.1f}, max={values.max():.1f}, mean={values.mean():.1f}, std={values.std():.2f}, unique={values.nunique()}")
                
                # 5. Interpoler les NaN
                if pd.isna(values).sum() > 0:
                    n_nan = pd.isna(values).sum()
                    logger.warning(f"    ‚ö†Ô∏è  {n_nan} NaN, interpolation...")
                    values = pd.Series(values).interpolate(method='linear').fillna(method='bfill').fillna(method='ffill').values
                
                df_clean[var_name] = values
                
                logger.info(f"    ‚úÖ min={values.min():.2f}, max={values.max():.2f}, mean={values.mean():.2f}")
                
            elif var_name == 'categorie':
                # G√©n√©rer les cat√©gories
                logger.warning(f"    ‚ö†Ô∏è  Cat√©gorie manquante, g√©n√©ration...")
                df_clean = self.generate_categories(df_clean)
                logger.info(f"    ‚úÖ Cat√©gories g√©n√©r√©es (30% / 50% / 20%)")
            else:
                logger.error(f"    ‚ùå Variable manquante: {var_name}")
                sys.exit(1)
        
        return df_clean
    
    def generate_categories(self, df: pd.DataFrame) -> pd.DataFrame:
        """G√©n√®re les 3 cat√©gories avec distribution 30/50/20"""
        n = len(df)
        n_cat1 = int(n * 0.30)
        n_cat2 = int(n * 0.50)
        n_cat3 = n - n_cat1 - n_cat2
        
        categories = np.concatenate([
            np.ones(n_cat1, dtype=int) * 1,
            np.ones(n_cat2, dtype=int) * 2,
            np.ones(n_cat3, dtype=int) * 3
        ])
        
        np.random.seed(42)
        np.random.shuffle(categories)
        df['categorie'] = categories
        
        return df
    
    # ========================================================================
    # √âTAPE 3 : V√âRIFICATION DES COH√âRENCES PHYSIQUES
    # ========================================================================
    
    def verify_physical_coherence(self, df: pd.DataFrame) -> pd.DataFrame:
        """V√©rifie et corrige les incoh√©rences physiques"""
        logger.info("\n" + "="*70)
        logger.info("üî¨ √âTAPE 3 : V√âRIFICATION DES COH√âRENCES PHYSIQUES")
        logger.info("="*70)
        
        n_corrections = 0
        
        # 1. Coh√©rence temp√©ratures : tmin ‚â§ tmean ‚â§ tmax
        logger.info("\n  ‚Ä¢ V√©rification tmin ‚â§ tmean ‚â§ tmax...")
        incoherent = (df['tmin'] > df['tmean']) | (df['tmean'] > df['tmax'])
        n_incoherent = incoherent.sum()
        
        if n_incoherent > 0:
            logger.warning(f"    ‚ö†Ô∏è  {n_incoherent} incoh√©rences d√©tect√©es, correction...")
            
            # Correction : recalculer tmean
            df.loc[incoherent, 'tmean'] = (df.loc[incoherent, 'tmin'] + df.loc[incoherent, 'tmax']) / 2
            n_corrections += n_incoherent
            
            logger.info(f"    ‚úÖ {n_incoherent} corrections appliqu√©es")
        else:
            logger.info(f"    ‚úÖ Aucune incoh√©rence")
        
        # 2. Coh√©rence ETo vs temp√©rature
        logger.info("\n  ‚Ä¢ V√©rification ETo coh√©rent avec temp√©rature...")
        # ETo doit augmenter avec la temp√©rature
        eto_expected = 0.0023 * (df['tmean'] + 17.8) * np.sqrt((df['tmax'] - df['tmin']).clip(lower=0)) * df['Ra']
        eto_expected = eto_expected.clip(lower=0.5, upper=12.0)
        
        # Remplacer les valeurs trop √©loign√©es
        eto_diff = np.abs(df['ETo'] - eto_expected)
        large_diff = eto_diff > 3.0
        n_large_diff = large_diff.sum()
        
        if n_large_diff > 0:
            logger.warning(f"    ‚ö†Ô∏è  {n_large_diff} valeurs ETo aberrantes, recalcul...")
            df.loc[large_diff, 'ETo'] = eto_expected[large_diff]
            n_corrections += n_large_diff
            logger.info(f"    ‚úÖ {n_large_diff} corrections appliqu√©es")
        else:
            logger.info(f"    ‚úÖ ETo coh√©rent")
        
        # 3. Coh√©rence VPD vs humidit√©
        logger.info("\n  ‚Ä¢ V√©rification VPD coh√©rent avec humidit√©...")
        # VPD doit diminuer quand humidit√© augmente
        es = 0.6108 * np.exp((17.27 * df['tmean']) / (df['tmean'] + 237.3))
        ea = es * (df['humidite'] / 100.0)
        vpd_expected = (es - ea).clip(lower=0.1, upper=5.0)
        
        vpd_diff = np.abs(df['VPD'] - vpd_expected)
        large_diff = vpd_diff > 1.5
        n_large_diff = large_diff.sum()
        
        if n_large_diff > 0:
            logger.warning(f"    ‚ö†Ô∏è  {n_large_diff} valeurs VPD aberrantes, recalcul...")
            df.loc[large_diff, 'VPD'] = vpd_expected[large_diff]
            n_corrections += n_large_diff
            logger.info(f"    ‚úÖ {n_large_diff} corrections appliqu√©es")
        else:
            logger.info(f"    ‚úÖ VPD coh√©rent")
        
        # 4. Coh√©rence soil_temp vs tmean
        logger.info("\n  ‚Ä¢ V√©rification temp√©rature sol coh√©rente...")
        # soil_temp ~ tmean (¬± quelques degr√©s)
        soil_temp_expected = df['tmean'] + np.random.normal(0, 2, len(df))
        soil_temp_expected = soil_temp_expected.clip(lower=5, upper=40)
        
        soil_diff = np.abs(df['soil_temp'] - df['tmean'])
        large_diff = soil_diff > 10
        n_large_diff = large_diff.sum()
        
        if n_large_diff > 0:
            logger.warning(f"    ‚ö†Ô∏è  {n_large_diff} valeurs soil_temp aberrantes, correction...")
            df.loc[large_diff, 'soil_temp'] = soil_temp_expected[large_diff]
            n_corrections += n_large_diff
            logger.info(f"    ‚úÖ {n_large_diff} corrections appliqu√©es")
        else:
            logger.info(f"    ‚úÖ Temp√©rature sol coh√©rente")
        
        logger.info(f"\n  üìä Total corrections physiques: {n_corrections}")
        
        return df
    
    # ========================================================================
    # √âTAPE 4 : G√âN√âRATION DES OUTPUTS
    # ========================================================================
    
    def generate_outputs(self, df: pd.DataFrame) -> pd.DataFrame:
        """G√©n√®re pump_status et irrigation_volume avec logique intelligente"""
        logger.info("\n" + "="*70)
        logger.info("üíß √âTAPE 4 : G√âN√âRATION DES OUTPUTS")
        logger.info("="*70)
        
        # 1. Calculer le score de besoin d'irrigation
        logger.info("\n  ‚Ä¢ Calcul du score de besoin d'irrigation...")
        
        # Normaliser les variables
        soil_moisture_norm = (df['soil_moisture'] - df['soil_moisture'].min()) / (df['soil_moisture'].max() - df['soil_moisture'].min())
        eto_norm = (df['ETo'] - df['ETo'].min()) / (df['ETo'].max() - df['ETo'].min())
        temp_norm = (df['tmean'] - df['tmean'].min()) / (df['tmean'].max() - df['tmean'].min())
        vpd_norm = (df['VPD'] - df['VPD'].min()) / (df['VPD'].max() - df['VPD'].min())
        
        # Score multi-crit√®res
        irrigation_need_score = (
            (1 - soil_moisture_norm) * 0.40 +  # 40% : sol sec ‚Üí besoin √©lev√©
            eto_norm * 0.30 +                   # 30% : ETo √©lev√© ‚Üí besoin √©lev√©
            temp_norm * 0.15 +                  # 15% : temp√©rature √©lev√©e
            vpd_norm * 0.15                     # 15% : VPD √©lev√© ‚Üí stress hydrique
        )
        
        # 2. D√©cision pump_status (seuil m√©dian pour 50/50)
        logger.info("\n  ‚Ä¢ Attribution pump_status (objectif: 50% OFF / 50% ON)...")
        
        threshold = irrigation_need_score.median()
        df['pump_status'] = (irrigation_need_score > threshold).astype(int)
        
        off_count = (df['pump_status'] == 0).sum()
        on_count = (df['pump_status'] == 1).sum()
        
        logger.info(f"    ‚úÖ Pump OFF: {off_count} ({off_count/len(df)*100:.1f}%)")
        logger.info(f"    ‚úÖ Pump ON: {on_count} ({on_count/len(df)*100:.1f}%)")
        
        # 3. Calculer irrigation_volume
        logger.info("\n  ‚Ä¢ Calcul irrigation_volume...")
        
        # Besoin en eau = ETo √ó Kc
        df['Kc'] = df['categorie'].map(self.KC_VALUES)
        water_need = (df['ETo'] * df['Kc']).clip(lower=0, upper=15.0)
        
        # Volume = besoin si ON, sinon 0
        df['irrigation_volume'] = np.where(df['pump_status'] == 1, water_need, 0.0)
        
        # Supprimer Kc temporaire
        df = df.drop('Kc', axis=1)
        
        vol_mean_off = df[df['pump_status'] == 0]['irrigation_volume'].mean()
        vol_mean_on = df[df['pump_status'] == 1]['irrigation_volume'].mean()
        
        logger.info(f"    ‚úÖ Volume moyen OFF: {vol_mean_off:.2f} mm/j")
        logger.info(f"    ‚úÖ Volume moyen ON: {vol_mean_on:.2f} mm/j")
        
        return df
    
    # ========================================================================
    # √âTAPE 5 : V√âRIFICATION DES COH√âRENCES LOGIQUES
    # ========================================================================
    
    def verify_logical_coherence(self, df: pd.DataFrame) -> pd.DataFrame:
        """V√©rifie et corrige les incoh√©rences logiques"""
        logger.info("\n" + "="*70)
        logger.info("üîç √âTAPE 5 : V√âRIFICATION DES COH√âRENCES LOGIQUES")
        logger.info("="*70)
        
        # 1. Coh√©rence : pump_status=0 ‚Üí irrigation_volume=0
        logger.info("\n  ‚Ä¢ V√©rification : OFF ‚Üí volume=0...")
        
        incoherent = (df['pump_status'] == 0) & (df['irrigation_volume'] > 0)
        n_incoherent = incoherent.sum()
        
        if n_incoherent > 0:
            logger.warning(f"    ‚ö†Ô∏è  {n_incoherent} incoh√©rences d√©tect√©es, correction...")
            df.loc[incoherent, 'irrigation_volume'] = 0.0
            logger.info(f"    ‚úÖ {n_incoherent} corrections appliqu√©es")
        else:
            logger.info(f"    ‚úÖ Aucune incoh√©rence")
        
        # 2. Coh√©rence : pump_status=1 ‚Üí irrigation_volume>0
        logger.info("\n  ‚Ä¢ V√©rification : ON ‚Üí volume>0...")
        
        incoherent = (df['pump_status'] == 1) & (df['irrigation_volume'] == 0)
        n_incoherent = incoherent.sum()
        
        if n_incoherent > 0:
            logger.warning(f"    ‚ö†Ô∏è  {n_incoherent} incoh√©rences d√©tect√©es, correction...")
            # Calculer un volume minimum bas√© sur ETo
            df.loc[incoherent, 'irrigation_volume'] = (df.loc[incoherent, 'ETo'] * 0.8).clip(lower=2.0, upper=8.0)
            logger.info(f"    ‚úÖ {n_incoherent} corrections appliqu√©es")
        else:
            logger.info(f"    ‚úÖ Coh√©rent")
        
        # 3. V√©rifier distribution par cat√©gorie
        logger.info("\n  ‚Ä¢ V√©rification distribution par cat√©gorie...")
        
        for cat in [1, 2, 3]:
            df_cat = df[df['categorie'] == cat]
            off_cat = (df_cat['pump_status'] == 0).sum()
            on_cat = (df_cat['pump_status'] == 1).sum()
            
            logger.info(f"    ‚Ä¢ Cat√©gorie {cat}: OFF={off_cat}, ON={on_cat}")
            
            if off_cat == 0 or on_cat == 0:
                logger.warning(f"      ‚ö†Ô∏è  Cat√©gorie {cat} d√©s√©quilibr√©e!")
        
        return df
    
    # ========================================================================
    # √âTAPE 6 : VALIDATION FINALE
    # ========================================================================
    
    def final_validation(self, df: pd.DataFrame) -> bool:
        """Validation finale compl√®te"""
        logger.info("\n" + "="*70)
        logger.info("‚úÖ √âTAPE 6 : VALIDATION FINALE")
        logger.info("="*70)
        
        all_valid = True
        
        # 1. V√©rifier les 10 inputs
        logger.info("\n  üì• V√©rification des 10 INPUTS:")
        for i, (var_name, var_info) in enumerate(self.INPUTS.items(), 1):
            if var_name in df.columns:
                values = df[var_name]
                min_val = values.min()
                max_val = values.max()
                in_range = (min_val >= var_info['min']) and (max_val <= var_info['max'])
                status = "‚úÖ" if in_range else "‚ùå"
                
                logger.info(f"    {status} {i:2d}. {var_name:20s} [{min_val:7.2f}, {max_val:7.2f}] {var_info['unit']}")
                
                if not in_range:
                    all_valid = False
            else:
                logger.error(f"    ‚ùå {var_name} MANQUANT")
                all_valid = False
        
        # 2. V√©rifier les 2 outputs
        logger.info("\n  üì§ V√©rification des 2 OUTPUTS:")
        
        # pump_status
        if 'pump_status' in df.columns:
            unique_vals = sorted(df['pump_status'].unique())
            has_both = (0 in unique_vals) and (1 in unique_vals)
            status = "‚úÖ" if has_both else "‚ùå"
            
            off = (df['pump_status'] == 0).sum()
            on = (df['pump_status'] == 1).sum()
            
            logger.info(f"    {status} 1. pump_status: OFF={off}, ON={on}")
            
            if not has_both:
                all_valid = False
        else:
            logger.error(f"    ‚ùå pump_status MANQUANT")
            all_valid = False
        
        # irrigation_volume
        if 'irrigation_volume' in df.columns:
            min_vol = df['irrigation_volume'].min()
            max_vol = df['irrigation_volume'].max()
            in_range = (min_vol >= 0) and (max_vol <= 15.0)
            status = "‚úÖ" if in_range else "‚ùå"
            
            logger.info(f"    {status} 2. irrigation_volume: [{min_vol:.2f}, {max_vol:.2f}] mm/j")
            
            if not in_range:
                all_valid = False
        else:
            logger.error(f"    ‚ùå irrigation_volume MANQUANT")
            all_valid = False
        
        # 3. V√©rifier coh√©rences
        logger.info("\n  üîç V√©rification coh√©rences:")
        
        # OFF ‚Üí volume=0
        incoherent_off = ((df['pump_status'] == 0) & (df['irrigation_volume'] > 0)).sum()
        status_off = "‚úÖ" if incoherent_off == 0 else "‚ùå"
        logger.info(f"    {status_off} OFF ‚Üí volume=0: {incoherent_off} incoh√©rences")
        if incoherent_off > 0:
            all_valid = False
        
        # ON ‚Üí volume>0
        incoherent_on = ((df['pump_status'] == 1) & (df['irrigation_volume'] == 0)).sum()
        status_on = "‚úÖ" if incoherent_on == 0 else "‚ö†Ô∏è "
        logger.info(f"    {status_on} ON ‚Üí volume>0: {incoherent_on} exceptions")
        
        # 4. Distribution
        logger.info("\n  üìä Distribution finale:")
        logger.info(f"    ‚Ä¢ Total lignes: {len(df)}")
        logger.info(f"    ‚Ä¢ P√©riode: {df['date'].min()} ‚Üí {df['date'].max()}")
        
        for cat in [1, 2, 3]:
            count = (df['categorie'] == cat).sum()
            pct = count / len(df) * 100
            logger.info(f"    ‚Ä¢ Cat√©gorie {cat}: {count} ({pct:.1f}%)")
        
        return all_valid
    
    # ========================================================================
    # √âTAPE 7 : SAUVEGARDE
    # ========================================================================
    
    def save_final_dataset(self, df: pd.DataFrame, output_file: str):
        """Sauvegarde le dataset final"""
        logger.info("\n" + "="*70)
        logger.info("üíæ √âTAPE 7 : SAUVEGARDE")
        logger.info("="*70)
        
        # S√©lectionner colonnes finales (10 inputs + 2 outputs + date)
        final_columns = ['date'] + list(self.INPUTS.keys()) + list(self.OUTPUTS.keys())
        df_final = df[final_columns].copy()
        
        # Sauvegarder
        os.makedirs(os.path.dirname(output_file) or '.', exist_ok=True)
        df_final.to_csv(output_file, index=False)
        
        logger.info(f"\n‚úÖ Dataset final sauvegard√©: {output_file}")
        logger.info(f"üìä {len(df_final)} lignes √ó {len(df_final.columns)} colonnes")
        
        # Afficher √©chantillon
        logger.info(f"\nüìã √âCHANTILLON (5 premi√®res lignes):")
        print(df_final.head().to_string())
    
    # ========================================================================
    # PIPELINE COMPLET
    # ========================================================================
    
    def generate(self, input_file: str, output_file: str):
        """Pipeline complet de g√©n√©ration"""
        
        logger.info("="*70)
        logger.info("üöÄ G√âN√âRATION DU DATASET FINAL")
        logger.info("="*70)
        logger.info(f"üìÖ Date: 2025-11-21 18:55:53 UTC")
        logger.info(f"üë§ Utilisateur: Yassinechouk")
        logger.info("="*70)
        
        # √âTAPE 1 : Chargement
        df = self.load_merged_data(input_file)
        
        # √âTAPE 2 : S√©lection et conversion inputs
        df = self.select_and_convert_inputs(df)
        
        # √âTAPE 3 : V√©rification coh√©rences physiques
        df = self.verify_physical_coherence(df)
        
        # √âTAPE 4 : G√©n√©ration outputs
        df = self.generate_outputs(df)
        
        # √âTAPE 5 : V√©rification coh√©rences logiques
        df = self.verify_logical_coherence(df)
        
        # √âTAPE 6 : Validation finale
        is_valid = self.final_validation(df)
        
        if not is_valid:
            logger.error("\n‚ùå VALIDATION √âCHOU√âE - Corrections n√©cessaires")
            sys.exit(1)
        
        # √âTAPE 7 : Sauvegarde
        self.save_final_dataset(df, output_file)
        
        logger.info("\n" + "="*70)
        logger.info("üéâ G√âN√âRATION TERMIN√âE AVEC SUCC√àS!")
        logger.info("="*70)
        logger.info(f"\nüöÄ Prochaine √©tape:")
        logger.info(f"   python train_final.py --input {output_file} --optimize")
        logger.info("="*70)


def main():
    parser = argparse.ArgumentParser(description="G√©n√©ration du dataset final parfait")
    parser.add_argument('--input', type=str, required=True, help='Fichier merged (data/merged_all.csv)')
    parser.add_argument('--output', type=str, default='tunisia_irrigation_final_corrected.csv', help='Fichier de sortie')
    
    args = parser.parse_args()
    
    try:
        generator = FinalDatasetGenerator()
        generator.generate(args.input, args.output)
        
    except Exception as e:
        logger.error(f"\n‚ùå Erreur: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()