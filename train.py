#!/usr/bin/env python3
"""
Script d'Entra√Ænement - Mod√®les XGBoost pour ESP32-S3
Auteur: Yassinechouk
Date: 2025-11-22

Entra√Æne 2 mod√®les optimis√©s pour ESP32:
1. Classification : pump_status (OFF/ON)
2. R√©gression : irrigation_volume (mm/jour)

INPUTS (5 variables capteurs ESP32):
- ETo (Evapotranspiration)
- VPD (Vapor Pressure Deficit)
- soil_moisture (Humidit√© du sol)
- soil_temp (Temp√©rature du sol)
- categorie (Type de culture: 1/2/3)

OUTPUTS:
- pump_status (0=OFF, 1=ON)
- irrigation_volume (mm/jour)
"""

import pandas as pd
import numpy as np
import joblib
import json
import os
import sys
import logging
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# Import XGBoost
try:
    from xgboost import XGBClassifier, XGBRegressor
    XGBOOST_AVAILABLE = True
except ImportError:
    print("‚ùå ERREUR: XGBoost non install√©")
    print("Installation: pip install xgboost")
    sys.exit(1)

# Import scikit-learn
try:
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.metrics import (
        accuracy_score, precision_score, recall_score, f1_score,
        confusion_matrix, classification_report,
        r2_score, mean_absolute_error, mean_squared_error
    )
    from sklearn.preprocessing import StandardScaler
    from typing import Optional, Dict, Any, TYPE_CHECKING
    
    if TYPE_CHECKING:
        import numpy.typing as npt
except ImportError:
    print("‚ùå ERREUR: scikit-learn non install√©")
    print("Installation: pip install scikit-learn")
    sys.exit(1)

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class ESP32IrrigationTrainer:
    """Entra√Æneur de mod√®les d'irrigation pour ESP32-S3"""
    
    def __init__(self, dataset_path):
        self.dataset_path = dataset_path
        self.df = pd.DataFrame()
        self.X_train = pd.DataFrame()
        self.X_test = pd.DataFrame()
        self.y_pump_train = pd.Series(dtype=int)
        self.y_pump_test = pd.Series(dtype=int)
        self.y_vol_train = pd.Series(dtype=float)
        self.y_vol_test = pd.Series(dtype=float)
        self.clf: Optional[XGBClassifier] = None
        self.reg: Optional[XGBRegressor] = None
        self.scaler: Optional[StandardScaler] = None
        
        # ‚ö° Features ESP32 (5 variables uniquement)
        self.input_features = [
            'ETo',           # Evapotranspiration
            'VPD',           # Vapor Pressure Deficit
            'soil_moisture', # Humidit√© du sol (capteur)
            'soil_temp',     # Temp√©rature du sol (capteur)
            'categorie'      # Type de culture (1/2/3)
        ]
        
        # Variables de sortie (2 variables)
        self.outputs = ['pump_status', 'irrigation_volume']
    
    def load_data(self):
        """Charge et v√©rifie les donn√©es"""
        logger.info("="*70)
        logger.info("üìÇ √âTAPE 1 : CHARGEMENT DES DONN√âES (ESP32 MODE)")
        logger.info("="*70)
        
        # V√©rifier existence fichier
        if not os.path.exists(self.dataset_path):
            logger.error(f"‚ùå Fichier introuvable: {self.dataset_path}")
            raise FileNotFoundError(f"Fichier non trouv√©: {self.dataset_path}")
        
        # Charger CSV
        try:
            self.df = pd.read_csv(self.dataset_path)
            logger.info(f"  ‚úÖ Charg√©: {len(self.df)} lignes √ó {len(self.df.columns)} colonnes")
        except Exception as e:
            logger.error(f"‚ùå Erreur lecture CSV: {str(e)}")
            raise
        
        # V√©rifier colonnes requises
        missing = []
        for col in self.input_features + self.outputs:
            if col not in self.df.columns:
                missing.append(col)
        
        if missing:
            logger.error(f"‚ùå Colonnes manquantes: {missing}")
            logger.info(f"üìã Colonnes disponibles: {list(self.df.columns)}")
            raise ValueError(f"Colonnes manquantes: {missing}")
        
        logger.info(f"  ‚úÖ Toutes les colonnes ESP32 pr√©sentes")
        
        # Afficher info dataset
        logger.info(f"\n  üìä Informations dataset:")
        logger.info(f"    ‚Ä¢ Taille: {len(self.df)} lignes")
        logger.info(f"    ‚Ä¢ Features ESP32: {len(self.input_features)} variables")
        logger.info(f"    ‚Ä¢ Variables: {', '.join(self.input_features)}")
        
        return self
    
    def clean_data(self):
        """Nettoie les donn√©es"""
        logger.info("\n" + "="*70)
        logger.info("üßπ √âTAPE 2 : NETTOYAGE DES DONN√âES")
        logger.info("="*70)
        
        n_before = len(self.df)
        
        # G√©rer les NaN
        n_nan = self.df[self.input_features + self.outputs].isnull().sum().sum()
        
        if n_nan > 0:
            logger.warning(f"  ‚ö†Ô∏è  {n_nan} valeurs NaN d√©tect√©es")
            
            # Remplir NaN dans inputs par m√©diane
            for col in self.input_features:
                if self.df[col].isnull().any():
                    n_col_nan = self.df[col].isnull().sum()
                    median_val = self.df[col].median()
                    self.df[col].fillna(median_val, inplace=True)
                    logger.info(f"    ‚Ä¢ {col}: {n_col_nan} NaN ‚Üí m√©diane ({median_val:.2f})")
            
            # Supprimer lignes avec NaN dans outputs
            self.df.dropna(subset=self.outputs, inplace=True)
            logger.info(f"  ‚úÖ Lignes avec NaN outputs supprim√©es")
        
        # Convertir types
        for col in self.input_features + self.outputs:
            if col == 'categorie' or col == 'pump_status':
                self.df[col] = self.df[col].astype(int)
            else:
                self.df[col] = pd.to_numeric(self.df[col], errors='coerce')
        
        # Supprimer lignes avec valeurs aberrantes apr√®s conversion
        self.df.dropna(subset=self.input_features + self.outputs, inplace=True)
        
        n_after = len(self.df)
        n_removed = n_before - n_after
        
        if n_removed > 0:
            logger.info(f"  üìä {n_removed} lignes supprim√©es ({n_removed/n_before*100:.1f}%)")
        
        logger.info(f"  ‚úÖ Dataset nettoy√©: {n_after} lignes restantes")
        
        # V√©rifier distribution pump_status
        logger.info(f"\n  üìä Distribution pump_status:")
        off = (self.df['pump_status'] == 0).sum()
        on = (self.df['pump_status'] == 1).sum()
        
        logger.info(f"    ‚Ä¢ OFF (0): {off} ({off/len(self.df)*100:.1f}%)")
        logger.info(f"    ‚Ä¢ ON (1): {on} ({on/len(self.df)*100:.1f}%)")
        
        if off == 0 or on == 0:
            raise ValueError("pump_status doit contenir √† la fois 0 et 1")
        
        # V√©rifier coh√©rence logique
        incoherent = ((self.df['pump_status'] == 0) & (self.df['irrigation_volume'] > 0)).sum()
        if incoherent > 0:
            logger.warning(f"  ‚ö†Ô∏è  {incoherent} incoh√©rences (OFF mais volume>0), correction...")
            self.df.loc[self.df['pump_status'] == 0, 'irrigation_volume'] = 0.0
        
        logger.info(f"  ‚úÖ Donn√©es coh√©rentes")
        
        # Afficher statistiques des features ESP32
        logger.info(f"\n  üìä Statistiques Features ESP32:")
        for col in self.input_features:
            if col != 'categorie':
                logger.info(f"    ‚Ä¢ {col:15s}: min={self.df[col].min():.2f}, max={self.df[col].max():.2f}, mean={self.df[col].mean():.2f}")
            else:
                logger.info(f"    ‚Ä¢ {col:15s}: valeurs={sorted(self.df[col].unique())}")
        
        return self
    
    def split_data(self, test_size=0.2, random_state=42):
        """Split train/test"""
        logger.info("\n" + "="*70)
        logger.info("‚úÇÔ∏è √âTAPE 3 : SPLIT TRAIN/TEST")
        logger.info("="*70)
        
        # Extraire X et y
        X = self.df[self.input_features].copy()
        y_pump = self.df['pump_status'].copy()
        y_vol = self.df['irrigation_volume'].copy()
        
        logger.info(f"  üìä Total √©chantillons: {len(X)}")
        
        # Normalisation
        logger.info(f"  üîß Normalisation des features ESP32...")
        self.scaler = StandardScaler()
        X_scaled = self.scaler.fit_transform(X)
        X = pd.DataFrame(X_scaled, columns=self.input_features)
        
        # Split avec stratification
        try:
            X_train_arr, X_test_arr, y_pump_train_arr, y_pump_test_arr = train_test_split(
                X, y_pump, 
                test_size=test_size, 
                random_state=random_state,
                stratify=y_pump
            )
            logger.info(f"  ‚úÖ Split avec stratification")
        except:
            logger.warning(f"  ‚ö†Ô∏è  Stratification impossible, split normal...")
            X_train_arr, X_test_arr, y_pump_train_arr, y_pump_test_arr = train_test_split(
                X, y_pump, 
                test_size=test_size, 
                random_state=random_state
            )
        
        # Convertir en DataFrame/Series avec reset_index
        self.X_train = pd.DataFrame(X_train_arr, columns=self.input_features)
        self.X_test = pd.DataFrame(X_test_arr, columns=self.input_features)
        self.y_pump_train = pd.Series(y_pump_train_arr, dtype=int).reset_index(drop=True)
        self.y_pump_test = pd.Series(y_pump_test_arr, dtype=int).reset_index(drop=True)
        
        # Split y_vol avec m√™mes indices
        y_vol_train_arr = y_vol.iloc[y_pump_train_arr.index].values
        y_vol_test_arr = y_vol.iloc[y_pump_test_arr.index].values
        
        self.y_vol_train = pd.Series(y_vol_train_arr, dtype=float).reset_index(drop=True)
        self.y_vol_test = pd.Series(y_vol_test_arr, dtype=float).reset_index(drop=True)
        
        logger.info(f"\n  üìä R√©partition:")
        logger.info(f"    ‚Ä¢ Train: {len(self.X_train)} ({len(self.X_train)/len(X)*100:.0f}%)")
        logger.info(f"    ‚Ä¢ Test:  {len(self.X_test)} ({len(self.X_test)/len(X)*100:.0f}%)")
        
        # Distribution
        train_off = (self.y_pump_train == 0).sum()
        train_on = (self.y_pump_train == 1).sum()
        test_off = (self.y_pump_test == 0).sum()
        test_on = (self.y_pump_test == 1).sum()
        
        logger.info(f"\n  üìä Distribution:")
        logger.info(f"    ‚Ä¢ Train: OFF={train_off}, ON={train_on}")
        logger.info(f"    ‚Ä¢ Test:  OFF={test_off}, ON={test_on}")
        
        return self
    
    def train_classification(self):
        """Entra√Æne mod√®le classification (optimis√© ESP32)"""
        logger.info("\n" + "="*70)
        logger.info("ü§ñ √âTAPE 4 : CLASSIFICATION (pump_status) - ESP32 OPTIMIZED")
        logger.info("="*70)
        
        logger.info("  ‚è≥ Entra√Ænement en cours...")
        
        # Param√®tres optimis√©s pour ESP32 (mod√®le plus compact)
        self.clf = XGBClassifier(
            n_estimators=100,      # R√©duit pour ESP32
            max_depth=4,           # R√©duit pour mod√®le compact
            learning_rate=0.05,
            subsample=0.8,
            colsample_bytree=0.8,
            random_state=42,
            eval_metric='logloss',
            verbosity=0
        )
        
        # Entra√Ænement
        self.clf.fit(self.X_train, self.y_pump_train)
        logger.info("  ‚úÖ Entra√Ænement termin√©")
        
        # Pr√©dictions
        y_pred = self.clf.predict(self.X_test)
        
        # M√©triques
        acc = accuracy_score(self.y_pump_test, y_pred)
        prec = precision_score(self.y_pump_test, y_pred, zero_division=0)
        rec = recall_score(self.y_pump_test, y_pred, zero_division=0)
        f1 = f1_score(self.y_pump_test, y_pred, zero_division=0)
        
        logger.info(f"\n  üìä R√âSULTATS:")
        logger.info(f"    ‚Ä¢ Accuracy:  {acc*100:.2f}%")
        logger.info(f"    ‚Ä¢ Precision: {prec*100:.2f}%")
        logger.info(f"    ‚Ä¢ Recall:    {rec*100:.2f}%")
        logger.info(f"    ‚Ä¢ F1-Score:  {f1*100:.2f}%")
        
        # Matrice de confusion
        cm = confusion_matrix(self.y_pump_test, y_pred)
        logger.info(f"\n  üìä Matrice de Confusion:")
        logger.info(f"              Pr√©dit OFF  Pr√©dit ON")
        logger.info(f"    R√©el OFF      {cm[0,0]:6d}     {cm[0,1]:6d}")
        logger.info(f"    R√©el ON       {cm[1,0]:6d}     {cm[1,1]:6d}")
        
        # Feature importance
        importances = pd.DataFrame({
            'feature': self.input_features,
            'importance': self.clf.feature_importances_
        }).sort_values('importance', ascending=False)
        
        logger.info(f"\n  üìä Importance des Features ESP32:")
        for i, row in importances.iterrows():
            logger.info(f"    {row['feature']:15s} {row['importance']:.4f} {'‚ñà' * int(row['importance']*50)}")
        
        return {
            'accuracy': float(acc),
            'precision': float(prec),
            'recall': float(rec),
            'f1_score': float(f1)
        }
    
    def train_regression(self):
        """Entra√Æne mod√®le r√©gression (optimis√© ESP32)"""
        logger.info("\n" + "="*70)
        logger.info("ü§ñ √âTAPE 5 : R√âGRESSION (irrigation_volume) - ESP32 OPTIMIZED")
        logger.info("="*70)
        
        logger.info("  ‚è≥ Entra√Ænement en cours...")
        
        # Param√®tres optimis√©s pour ESP32
        self.reg = XGBRegressor(
            n_estimators=100,      # R√©duit pour ESP32
            max_depth=4,           # R√©duit pour mod√®le compact
            learning_rate=0.05,
            subsample=0.8,
            random_state=42,
            verbosity=0
        )
        
        # Entra√Ænement
        self.reg.fit(self.X_train, self.y_vol_train)
        logger.info("  ‚úÖ Entra√Ænement termin√©")
        
        # Pr√©dictions
        y_pred = self.reg.predict(self.X_test)
        
        # Coh√©rence: OFF ‚Üí volume=0
        if self.clf is not None:
            y_pump_pred = self.clf.predict(self.X_test)
            y_pred_coherent = np.where(y_pump_pred == 0, 0.0, y_pred)
            y_pred_coherent = np.clip(y_pred_coherent, 0, 15)
        else:
            y_pred_coherent = np.clip(y_pred, 0, 15)
        
        # Convertir en array numpy
        y_vol_test_array = np.array(self.y_vol_test)
        y_pred_coherent_array = np.array(y_pred_coherent)
        
        # M√©triques
        r2 = r2_score(y_vol_test_array, y_pred_coherent_array)
        mae = mean_absolute_error(y_vol_test_array, y_pred_coherent_array)
        rmse = np.sqrt(mean_squared_error(y_vol_test_array, y_pred_coherent_array))
        
        logger.info(f"\n  üìä R√âSULTATS:")
        logger.info(f"    ‚Ä¢ R¬≤ Score: {r2:.4f}")
        logger.info(f"    ‚Ä¢ MAE:      {mae:.3f} mm/jour")
        logger.info(f"    ‚Ä¢ RMSE:     {rmse:.3f} mm/jour")
        
        # Feature importance
        importances = pd.DataFrame({
            'feature': self.input_features,
            'importance': self.reg.feature_importances_
        }).sort_values('importance', ascending=False)
        
        logger.info(f"\n  üìä Importance des Features ESP32:")
        for i, row in importances.iterrows():
            logger.info(f"    {row['feature']:15s} {row['importance']:.4f} {'‚ñà' * int(row['importance']*50)}")
        
        return {
            'r2': float(r2),
            'mae': float(mae),
            'rmse': float(rmse)
        }
    
    def save_models(self, output_dir='models_esp32'):
        """Sauvegarde les mod√®les pour ESP32"""
        logger.info("\n" + "="*70)
        logger.info("üíæ √âTAPE 6 : SAUVEGARDE (ESP32 FORMAT)")
        logger.info("="*70)
        
        # Cr√©er dossier
        os.makedirs(output_dir, exist_ok=True)
        
        # Chemins
        clf_path = os.path.join(output_dir, 'esp32_pump_classifier.pkl')
        reg_path = os.path.join(output_dir, 'esp32_volume_regressor.pkl')
        scaler_path = os.path.join(output_dir, 'esp32_scaler.pkl')
        meta_path = os.path.join(output_dir, 'esp32_metadata.json')
        
        joblib.dump(self.clf, clf_path)
        joblib.dump(self.reg, reg_path)
        joblib.dump(self.scaler, scaler_path)
        
        logger.info(f"  ‚úÖ {clf_path}")
        logger.info(f"  ‚úÖ {reg_path}")
        logger.info(f"  ‚úÖ {scaler_path}")
        
        # Extraire param√®tres scaler
        scaler_means: list = []
        scaler_scales: list = []
        if self.scaler is not None:
            try:
                # Acc√®s s√©curis√© aux attributs numpy array
                mean_attr = getattr(self.scaler, 'mean_', None)
                scale_attr = getattr(self.scaler, 'scale_', None)
                
                if mean_attr is not None:
                    scaler_means = mean_attr.tolist()
                if scale_attr is not None:
                    scaler_scales = scale_attr.tolist()
            except AttributeError:
                logger.warning("  ‚ö†Ô∏è  Impossible d'extraire param√®tres scaler")
                pass
        
        # M√©tadonn√©es ESP32
        metadata = {
            'date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'author': 'Yassinechouk',
            'target_device': 'ESP32-S3',
            'dataset': self.dataset_path,
            'n_total': len(self.df),
            'n_train': len(self.X_train),
            'n_test': len(self.X_test),
            'features': self.input_features,
            'n_features': len(self.input_features),
            'outputs': self.outputs,
            'scaler_means': scaler_means,
            'scaler_scales': scaler_scales,
            'model_type': 'XGBoost Compact (ESP32 Optimized)',
            'notes': 'Mod√®le optimis√© pour d√©ploiement sur ESP32-S3 avec 5 features capteurs'
        }
        
        with open(meta_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        
        logger.info(f"  ‚úÖ {meta_path}")
        
        logger.info(f"\n  üìä Tailles fichiers (ESP32):")
        logger.info(f"    ‚Ä¢ Classification: {os.path.getsize(clf_path)/1024:.1f} KB")
        logger.info(f"    ‚Ä¢ R√©gression:     {os.path.getsize(reg_path)/1024:.1f} KB")
        logger.info(f"    ‚Ä¢ Scaler:         {os.path.getsize(scaler_path)/1024:.1f} KB")
        logger.info(f"    ‚Ä¢ TOTAL:          {(os.path.getsize(clf_path) + os.path.getsize(reg_path) + os.path.getsize(scaler_path))/1024:.1f} KB")
        
        return self

    def run(self):
        """Pipeline complet ESP32"""
        logger.info("="*70)
        logger.info("üöÄ ENTRA√éNEMENT MOD√àLES IRRIGATION ESP32-S3")
        logger.info("="*70)
        logger.info(f"üìÖ Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info(f"üë§ Auteur: Yassinechouk")
        logger.info(f"üéØ Cible: ESP32-S3")
        logger.info(f"‚ö° Features: 5 variables capteurs")
        logger.info("="*70)
        
        try:
            self.load_data()
            self.clean_data()
            self.split_data()
            clf_metrics = self.train_classification()
            reg_metrics = self.train_regression()
            self.save_models()
            
            logger.info("\n" + "="*70)
            logger.info("üéâ ENTRA√éNEMENT TERMIN√â AVEC SUCC√àS! (ESP32 READY)")
            logger.info("="*70)
            
            logger.info(f"\nüìä PERFORMANCES:")
            logger.info(f"  Classification (Pump Status):")
            logger.info(f"    ‚Ä¢ Accuracy: {clf_metrics['accuracy']*100:.2f}%")
            logger.info(f"    ‚Ä¢ F1-Score: {clf_metrics['f1_score']*100:.2f}%")
            
            logger.info(f"\n  R√©gression (Volume):")
            logger.info(f"    ‚Ä¢ R¬≤:   {reg_metrics['r2']:.4f}")
            logger.info(f"    ‚Ä¢ MAE:  {reg_metrics['mae']:.3f} mm/jour")
            logger.info(f"    ‚Ä¢ RMSE: {reg_metrics['rmse']:.3f} mm/jour")
            
            logger.info(f"\nüíæ Mod√®les ESP32: models_esp32/")
            logger.info(f"‚ö° Features: ETo, VPD, soil_moisture, soil_temp, categorie")
            logger.info(f"üéØ Pr√©dictions: python predict_esp32.py")
            logger.info("="*70)
            
            return clf_metrics, reg_metrics
            
        except Exception as e:
            logger.error(f"\n‚ùå ERREUR: {str(e)}")
            import traceback
            traceback.print_exc()
            raise


def main():
    import argparse
    
    parser = argparse.ArgumentParser(
        description='Entra√Ænement mod√®les irrigation pour ESP32-S3',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemples:
  python train_irrigation_esp32.py
  python train_irrigation_esp32.py --input "C:/Users/yassi/OneDrive/Bureau/data ++/data/final_dataset.csv"
  python train_irrigation_esp32.py --output-dir models_esp32_v2
        """
    )
    
    parser.add_argument(
        '--input',
        type=str,
        default=r'C:\Users\yassi\OneDrive\Bureau\data ++\data\final_dataset.csv',
        help='Fichier CSV dataset'
    )
    
    parser.add_argument(
        '--output-dir',
        type=str,
        default='models_esp32',
        help='Dossier sortie mod√®les'
    )
    
    args = parser.parse_args()
    
    try:
        trainer = ESP32IrrigationTrainer(args.input)
        trainer.run()
        return 0
        
    except KeyboardInterrupt:
        logger.info("\n‚ö†Ô∏è  Interruption utilisateur")
        return 1
        
    except Exception as e:
        logger.error(f"\n‚ùå √âchec: {str(e)}")
        return 1


if __name__ == "__main__":
    sys.exit(main())